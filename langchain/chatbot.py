import getpass
import os
import sys
from langchain_core.messages import AIMessage
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
from typing_extensions import Annotated, TypedDict
from typing import Sequence

api = os.environ.get("OPEN_AI_TOKEN")
model = init_chat_model("gpt-5-mini", model_provider="openai"
                         , base_url="https://aihubmix.com/v1", api_key=api)


class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    language: str


prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability in {language}.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)




workflow = StateGraph(state_schema=State)
def call_model(state: State):
    prompt = prompt_template.invoke(state)
    response = model.invoke(prompt)
    return {"messages": response}



# Define the (single) node in the graph
workflow.add_edge(START, "model")
workflow.add_node("model", call_model)
app = workflow.compile(checkpointer=MemorySaver())

config = {"configurable": {"thread_id": "abc123"}}

def chat_loop():
    """å¯åŠ¨å‘½ä»¤è¡ŒèŠå¤©å¾ªç¯"""
    print("ğŸ¤– èŠå¤©æœºå™¨äººå·²å¯åŠ¨ï¼")
    print("æ”¯æŒçš„å‘½ä»¤ï¼š")
    print("  /language [lang] - åˆ‡æ¢è¯­è¨€ (ä¾‹å¦‚: /language Chinese)")
    print("  /quit - é€€å‡ºèŠå¤©")
    print("  /help - æ˜¾ç¤ºå¸®åŠ©")
    print()
    
    language = "Chinese"  # é»˜è®¤ä¸­æ–‡
    print(f"å½“å‰è¯­è¨€: {language}")
    print("å¼€å§‹èŠå¤©å§ï¼è¾“å…¥æ‚¨çš„é—®é¢˜...")
    print("-" * 50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
            
            if not user_input:
                continue
                
            # å¤„ç†å‘½ä»¤
            if user_input.startswith("/"):
                if user_input == "/quit" or user_input == "/exit":
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                elif user_input.startswith("/language"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) > 1:
                        language = parts[1]
                        print(f"ğŸŒ å·²åˆ‡æ¢åˆ° {language}")
                    else:
                        print("âŒ ç”¨æ³•: /language [è¯­è¨€]")
                    continue
                elif user_input == "/help":
                    print("ğŸ“‹ å¯ç”¨å‘½ä»¤:")
                    print("  /language [lang] - åˆ‡æ¢è¯­è¨€")
                    print("  /quit, /exit - é€€å‡º")
                    print("  /help - æ˜¾ç¤ºæ­¤å¸®åŠ©")
                    continue
                else:
                    print("â“ æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©")
                    continue
            
            # å¤„ç†æ­£å¸¸å¯¹è¯
            input_messages = [HumanMessage(user_input)]
            output = app.invoke({"messages": input_messages, "language": language}, config)
            
            # è·å–AIå›å¤
            ai_response = output["messages"][-1].content
            print(f"ğŸ¤– AI: {ai_response}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

# å¦‚æœæ˜¯ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œå¯åŠ¨èŠå¤©å¾ªç¯
if __name__ == "__main__":
    chat_loop()
else:
    # ä¿æŒå‘åå…¼å®¹ï¼Œå¦‚æœæ˜¯å¯¼å…¥ä½¿ç”¨ï¼Œæ‰§è¡ŒåŸæ¥çš„æµ‹è¯•ä»£ç 
    query1 = "Hi! I'm Bob. who are you"
    language = "Spanish"
    input_messages = [HumanMessage(query1)]
    output = app.invoke({"messages": input_messages, "language": language}, config)
    output["messages"][-1].pretty_print()  # output contains all messages in state
